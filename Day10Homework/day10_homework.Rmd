---
title: "Day 10 Homework"
output: 
  html_document:
    fig_height: 4
    fig_width: 7
    theme: flatly
---
### 0. Setup
```{r}
library(plyr)
library(ggplot2)
library(compute.es)

CCdata <- read.csv("CCdata.csv")
```

### 1. Find some relationship in your data (e.g., correlation, comparison of means, etc.) that is "significant" (don't worry too much about what that might mean).
```{r}
RTbyID <- ddply(CCdata, c("ID","Lang"), summarise, RTmean = round(mean(RT),3))

myttest <- with(RTbyID, t.test(x = RTmean[Lang == "B"], y = RTmean[Lang == "M"]), alternative = c("greater"))
```

### 2. Get an estimate of the effect size (e.g., the difference between means, or the correlation).
```{r}
myN <- length(unique(CCdata$ID))/2
myES <- tes(myttest$statistic, myN, myN)
myES$d
```

### 3. Simulate data with this effect size (either using mvrnorm or adding a simulated effect), but with a much smaller data sample.  In other words, simulate an underpowered study.
```{r}
nsim <- 10000

results.table <- data.frame(meanB = rep(NA, nsim), meanM = rep(NA, nsim), BminusM = rep(NA, nsim), pval = NA)

for(i in 1:nsim) {
  # I don't really understand the statistics behind calculating the effect size and then simulating data with an effect -- below I simulated two variables (B and M) using rnorm that are supposed to be equivalent to my two variables (B and M) above, and then an effect for each of my two variables using the effect size (myEST$d) that I calculated using my above t-test:
  mydata <- data.frame(B = rnorm(10), M = rnorm(10), effect1 = rnorm(10, mean = myES$d), effect2 = rnorm(10, mean = myES$d))
  
  # Then, based on the code you provided in the day 10 practice, I added each variable (B and M) to its respective effect size (effect1 and effect2) to create columns Beffect and Meffect:
  mydata$Beffect <- mydata$B + mydata$effect1
  mydata$Meffect <- mydata$M + mydata$effect2

  # Doing t-test using newly-calculated Beffect and Meffect columns:
  myttest <- t.test(mydata$Beffect, mydata$Meffect, alternative = c("greater"))
  
  # Adding resulting t-test results to results.table dataframe:
  means <- myttest$estimate
  BminusM <- myttest$estimate[1] - myttest$estimate[2]
  pval <- myttest$p.value
  results.table[i, ] <- c(means, BminusM, pval)
}
```

### 4. Examine the amount of effect-size inflation via the "significance filter" by looking at the effect sizes from the simulations, for just the sims where the effect turned out significant.
```{r}
alpha <- .05

# Filtering out the results that are significant:
results.sig <- filter(results.table, pval < alpha)

# Adding a column to the results table that indicates which simulations produced significant results:
results.table$significant <- results.table$pval < alpha

# Plotting all p-values:
ggplot(results.table, aes(pval)) + geom_histogram(fill = "darkturquoise") + geom_vline(xintercept = 0.05, linetype = 2) + theme_minimal()  

# Plotting all mean differences and coloring them based on whether they were significant:
ggplot(results.table, aes(BminusM)) + geom_histogram(aes(fill = significant)) + scale_fill_brewer(palette = "Set1") + geom_vline(xintercept = myES$d, linetype = 2) + facet_grid(significant ~ .) + theme_minimal()  
```